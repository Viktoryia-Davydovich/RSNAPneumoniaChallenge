# -*- coding: utf-8 -*-
"""pneumchallenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hJ5SQ4BYvpTg3ealwK8l1hK3Z7OoKQhh
"""

!pip install pydicom

from google.colab import drive
drive.mount('/content/drive')

!unzip '/content/drive/My Drive/Exam NET/train_images.zip' -d /content
!unzip '/content/drive/My Drive/Exam NET/test_images.zip' -d /content

# -*- coding: utf-8 -*-
"""PneumChallenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13QfUhKqfw1EzuLIQpIl1iv12cBhgKtn7
"""

#!/usr/bin/env python
# coding: utf-8

import os
import math
import random
import pathlib
import numpy as np
import pandas as pd
import tensorflow as tf
from skimage.transform import resize
import pydicom
import pylab
import cv2

print("Tensorflow version " + tf.__version__)


AUTOTUNE = tf.data.experimental.AUTOTUNE

train_data_path = '/content/train_images'
test_data_path = '/content/test_images'
labels = pd.read_csv('/content/stage_2_train_labels.csv')

train_samples_num = len(os.listdir(train_data_path))
test_samples_num = len(os.listdir(test_data_path))

BATCH_SIZE = 32
EPOCHS = 5 # better 50
STEPS_PER_EPOCH = int(train_samples_num / BATCH_SIZE)

# making a dictionary containing label data with paths to files
# KEY is PATH to image, VALUE is list of boxes, empty if Target equals to 0

def parse_labels(labels_df, data_path):
    # key - filenames, values - boxes
    labels_parsed = {}
    for index, row in labels_df.iterrows():
        filename = data_path + '/' + row['patientId'] + '.dcm'
        if filename not in labels_parsed:
            labels_parsed[filename] = []
        if row['Target'] == 1:
            labels_parsed[filename].append([row['x'], row['y'], row['width'], row['height']])
    return labels_parsed

def train_test_labels(image_path):
    valid_filenames = image_path[int(len(image_path) * 0.95) :]
    train_filenames = image_path[: int(len(image_path) * 0.95)]

    valid_labels = {}
    train_labels ={}

    for key in parsed_labels:
        if key in valid_filenames:
            valid_labels[key] = parsed_labels[key]
        elif key in train_filenames:
            train_labels[key] = parsed_labels[key]
    return train_labels, valid_labels

parsed_labels = parse_labels(labels, train_data_path)
image_filenames = list(parsed_labels.keys())

train_labels, valid_labels = train_test_labels(image_filenames)
train_filenames = list(train_labels.keys())
valid_filenames = list(valid_labels.keys())

train_images_num = len(train_filenames)
valid_images_num = len(valid_filenames)

class DatasetGenerator(tf.keras.utils.Sequence):

  def __init__(self,  filenames, batch_size, labels = None, shuffle=True, predict = False):
    self.labels = labels
    self.filenames = filenames
    self.predict = predict
    self.batch_size = batch_size
    self.shuffle = shuffle
    self.on_epoch_end()

  def on_epoch_end(self):
      if self.shuffle:
           np.random.shuffle(self.filenames)

  def __len__(self):
          if self.predict:
              return int(np.ceil(len(self.filenames) / self.batch_size))
          else:
              return int(len(self.filenames) / self.batch_size)

  def load_data(self, file, label=None):
      image = pydicom.dcmread(file).pixel_array

      if not self.predict: 
          image_mask = np.zeros(image.shape)
          if label:
              for box in label:
                  x, y, w, h = box
                  image_mask[int(x):int(x + w), int(y):int(y + h)] = 1
          image_mask = resize(image_mask, (256, 256)) > 0.5
          image_mask = np.expand_dims(image_mask, -1)

      image = resize(image, (256, 256))                      
      image = np.expand_dims(image, -1)

      if not self.predict:
          return image, image_mask
      else: return image

  def __getitem__(self, index):
          filenames = self.filenames[index * self.batch_size: (index + 1) * self.batch_size]
          if self.predict:
              images = [self.load_data(filename) for filename in filenames]
              images = np.array(images)
              return images, filenames
          else:
              images_masks = [self.load_data(filename, self.labels[filename]) for filename in filenames]
              images, masks = zip(*images_masks)
              images = np.array(images)
              masks = np.array(masks)
              return images, masks



train_generator = DatasetGenerator(train_filenames, BATCH_SIZE, train_labels, True, False)
valid_generator = DatasetGenerator(valid_filenames, BATCH_SIZE,valid_labels, False, False)

# swish activation

class Swish(tf.keras.layers.Activation):
    
    def __init__(self, activation, **kwargs):
        super(Swish, self).__init__(activation, **kwargs)
        self.__name__ = 'swish'

# swish activation function
def swish(x):
    return (tf.keras.backend.sigmoid(x) * x)

tf.keras.utils.get_custom_objects().update({'swish': Swish(swish)})

# define model
def create_network(input_size=(256,256,1)):
    inputs = tf.keras.layers.Input(input_size)
    
    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='swish', padding='same')(inputs)
    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='swish', padding='same')(conv1)
    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='swish', padding='same')(pool1)
    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='swish', padding='same')(conv2)
    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='swish', padding='same')(pool2)
    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='swish', padding='same')(conv3)
    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='swish', padding='same')(pool3)
    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='swish', padding='same')(conv4)
    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='swish', padding='same')(pool4)
    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)

    up6 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)
    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='swish', padding='same')(up6)
    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='swish', padding='same')(conv6)

    up7 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)
    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='swish', padding='same')(up7)
    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='swish', padding='same')(conv7)

    up8 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)
    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='swish', padding='same')(up8)
    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='swish', padding='same')(conv8)

    up9 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)
    conv9 = tf.keras.layers.Conv2D(32, (3, 3), activation='swish', padding='same')(up9)
    conv9 = tf.keras.layers.Conv2D(32, (3, 3), activation='swish', padding='same')(conv9)

    conv10 = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)

    return tf.keras.models.Model(inputs=[inputs], outputs=[conv10])

def dice_coef(y_true, y_pred, smooth=1):
    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=-1)
    return (2. * intersection + smooth) / (tf.keras.backend.sum(tf.keras.backend.square(y_true),-1) + tf.keras.backend.sum(tf.keras.backend.square(y_pred),-1) + smooth)

def dice_coef_loss(y_true, y_pred):
    return 1-dice_coef(y_true, y_pred)

# learning rate transformation
def lr_decay(x):
    lr = 0.0001
    epochs = 5
    return lr*(np.cos(np.pi*x/epochs)+1.)/2
  
learn_rate_decay_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay)

model = create_network()
model.compile(optimizer='adam',
              loss=dice_coef_loss,
              metrics=['accuracy', dice_coef])

model.summary()

# checkpoint
chkp_path = '/content/md.ckpt'
cp_callback = tf.keras.callbacks.ModelCheckpoint(chkp_path, save_weights_only=True)

history = model.fit_generator(train_generator, validation_data=valid_generator, 
                    callbacks=[learn_rate_decay_callback, cp_callback],
                    epochs=EPOCHS, use_multiprocessing=True, workers = 4)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,4))
plt.subplot(131)
plt.plot(history.epoch, history.history["loss"], label="Train loss")
plt.plot(history.epoch, history.history["val_loss"], label="Valid loss")
plt.legend()
plt.subplot(132)
plt.plot(history.epoch, history.history["acc"], label="Train accuracy")
plt.plot(history.epoch, history.history["val_acc"], label="Valid accuracy")
plt.legend()
plt.subplot(133)
plt.plot(history.epoch, history.history["dice_coeff"], label="Train dice_coeff")
plt.plot(history.epoch, history.history["val_dice_coeff"], label="Valid dice_coeff")
plt.legend()
plt.show()

model.save("/content/my_model.h5")

restored_model = tf.keras.models.load_model("/content/my_model.h5")

import pickle
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))

from skimage import measure

folder = '/content/test_images'
test_filenames = [folder + '/' + file for file in os.listdir(folder)]
test_generator = DatasetGenerator(test_filenames, BATCH_SIZE, None, False, True)

submission_dict = {}
for imgs, filenames in test_generator:
    preds = model.predict(imgs)
    for pred, filename in zip(preds, filenames):
        pred = resize(pred, (1024, 1024), mode='reflect')
        comp = pred[:, :, 0] > 0.5
        comp = measure.label(comp)
        predictionString = ''
        for region in measure.regionprops(comp):
            y, x, y2, x2 = region.bbox
            height = y2 - y
            width = x2 - x
            conf = np.mean(pred[y:y+height, x:x+width])
            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '
        filename = filename.split('.')[0]
        submission_dict[filename] = predictionString
    if len(submission_dict) >= len(test_filenames):
        break

# save dictionary as csv file
sub = pd.DataFrame.from_dict(submission_dict,orient='index')
sub.index.names = ['patientId']
sub.columns = ['PredictionString']
sub.to_csv('/content/submission.csv')

# Drawing colored borders aroun opacities
def draw_border(image, box):
    color = np.floor(np.random.rand(3) * 256).astype('int')
    border_width = 5
    
    box_int = [int(value) for value in box]
    x1, y1, h, w = box_int
    x2 = x1 + w
    y2 = y1 + h
    
    image[y1: y1 + border_width, x1: x2] = color
    image[y2: y2 + border_width, x1: x2] = color
    image[y1: y2, x1: x1  + border_width] = color
    image[y1: y2, x2: x2  + border_width] = color
    
    return image

def show_with_boxes(patient_data, path):
    if patient_data:
        lungs_data_dicom = pydicom.read_file(path)
        lungs_data = lungs_data_dicom.pixel_array
    
        # convert from 1D to 3D - for rgb
        lungs_data_rgb = np.stack([lungs_data] * 3, axis=2)
    
        # overlay colored borders onto opacities
        for box in patient_data['boxes']:
            image_rgb_border = draw_border(lungs_data_rgb, box)

        pylab.imshow(image_rgb_border, cmap=pylab.cm.gist_gray)
    else: pass

def show_predict(path_to_image, model):
  image = pydicom.dcmread(path_to_image).pixel_array
  image = resize(image, (256, 256))                      
  image = np.expand_dims(image, -1)
  image = np.expand_dims(image, 0)
  
  predicted_mask = model.predict(image)
  
  comp = pred[:, :, 0] > 0.5
  comp = measure.label(comp)
  boxes = []
  for region in measure.regionprops(comp):
    y, x, y2, x2 = region.bbox
    height = y2 - y
    width = x2 - x
    boxes.append(x,y,width,height)
  return boxes, path

path = '/content/train_images/00436515-870c-4b36-a041-de91049b9ab4.dcm'

show_predict(path, model)



image = pydicom.dcmread(path).pixel_array
  image = resize(image, (256, 256))                      
  image = np.expand_dims(image, -1)
  image = np.expand_dims(image, 0)
  image.shape

